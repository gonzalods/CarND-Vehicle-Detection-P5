{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VEHICLE DETECTION PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common attributes and functions\n",
    "### Map with the color scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convColor = {'YUV': cv2.COLOR_RGB2YUV, 'YCrCb': cv2.COLOR_RGB2YCrCb, \n",
    "            'HSV': cv2.COLOR_RGB2HSV, 'LUV': cv2.COLOR_RGB2LUV,\n",
    "            'HLS': cv2.COLOR_RGB2HLS, 'YUV': cv2.COLOR_RGB2YUV,\n",
    "            'YCrCb': cv2.COLOR_RGB2YCrCb, 'LAB': cv2.COLOR_RGB2LAB}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to return HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),transform_sqrt=False, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOG Features Extraction and Train a Linear SVM Classifier\n",
    "## HOG Features Extraction and Train-Test Examples Definition\n",
    "### Function to extract HOG features from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(imgs, cspace='RGB', orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0, spatial_size=(32,32), hist_bins=32):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "\n",
    "        # Convert to the selected color scale\n",
    "        if cspace != 'RGB':\n",
    "            feature_image = cv2.cvtColor(image, convColor[cspace])\n",
    "        else: feature_image = np.copy(image)      \n",
    "\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features)        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        \n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(hog_features)\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images files and split up time series vehicles images into train and test examples.\n",
    "In the vehicle dataset, the GIT* folders contain time-serie data. To optimize de classifier I split the images to make sure train and test images are suffient different from one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_train = []\n",
    "vehicles_test = []\n",
    "non_vehicles = []\n",
    "files = glob.glob('./clf_images/vehicles/GTI_Far/*.png')\n",
    "indx_test = int(len(files) * 0.2)\n",
    "vehicles_train.append(files[:indx_test])\n",
    "vehicles_test.append(files[indx_test:])\n",
    "files = glob.glob('./clf_images/vehicles/GTI_Left/*.png')\n",
    "indx_test = int(len(files) * 0.2)\n",
    "vehicles_train.append(files[:indx_test])\n",
    "vehicles_test.append(files[indx_test:])\n",
    "files = glob.glob('./clf_images/vehicles/GTI_MiddleClose/*.png')\n",
    "indx_test = int(len(files) * 0.2)\n",
    "vehicles_train.append(files[:indx_test])\n",
    "vehicles_test.append(files[indx_test:])\n",
    "files = glob.glob('./clf_images/vehicles/GTI_Right/*.png')\n",
    "indx_test = int(len(files) * 0.2)\n",
    "vehicles_train.append(files[:indx_test])\n",
    "vehicles_test.append(files[indx_test:])\n",
    "files = glob.glob('./clf_images/vehicles/KITTI_extracted/*.png')\n",
    "indx_test = int(len(files) * 0.2)\n",
    "vehicles_train.append(files[:indx_test])\n",
    "vehicles_test.append(files[indx_test:])\n",
    "vehicles_train = np.concatenate(vehicles_train)\n",
    "vehicles_test = np.concatenate(vehicles_test)\n",
    "print('# vehicles_train {} - vehicles_test'.format(len(vehicles_train)), len(vehicles_test))\n",
    "\n",
    "files = glob.glob('./clf_images/non-vehicles/GTI/*.png')\n",
    "non_vehicles.append(files)\n",
    "files = glob.glob('./clf_images/non-vehicles/Extras/*.png')\n",
    "non_vehicles.append(files)\n",
    "non_vehicles = np.concatenate(non_vehicles)\n",
    "print('# non vehicles {}'.format(len(non_vehicles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG features extraction parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorspace = 'YUV' # Can be RGB, HSV, HLS, YUV, YCrCb\n",
    "orient = 11\n",
    "pix_per_cell = 16\n",
    "cell_per_block = 2\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG features extraction from vehicles and non-vehicle images.\n",
    "The extraction of HOG features of the vehicle images is done separately for the training examples and the test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "car_features_train = extract_features(vehicles_train, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "car_features_test = extract_features(vehicles_test, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "\n",
    "notcar_features = extract_features(non_vehicles, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract HOG features...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up non-vehicles features into randomized training and test sets.\n",
    "The vehicle features ara already split. The non-vehicle labels vector is also defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = np.random.randint(0, 100)\n",
    "X_nc_train, X_nc_test, y_nc_train, y_nc_test = train_test_split(\n",
    "    notcar_features, np.zeros(len(notcar_features)), test_size=0.2, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an array stack of feature vectors, define the vehicles labels vectors and shuffle the train features and labels vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack((car_features_train, X_nc_train)).astype(np.float64)\n",
    "X_test  = np.vstack((car_features_test, X_nc_test)).astype(np.float64)\n",
    "\n",
    "y_train = np.hstack((np.ones(len(car_features_train)), y_nc_train))\n",
    "y_test = np.hstack((np.ones(len(car_features_test)), y_nc_test))\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainnig and Parameter Tuning the Linear SVM Classifier\n",
    "To tune the Linear SVM vehicle detection model, I used the `GridSearchCV` scikit-learn's parameter tuning algoritm.\n",
    "### Tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']}\n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "\n",
    "svr = SVC()\n",
    "clf = GridSearchCV(svr,param_grid)\n",
    "# Check the training time for the SVC\n",
    "\n",
    "t=time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access to the optimal parameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = clf.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Accuracy of SVC = ', round(clf.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {'svc': clf,\n",
    "          'orient': orient,\n",
    "          'colorspace': colorspace,\n",
    "          'pix_per_cell': pix_per_cell,\n",
    "          'cell_per_block': cell_per_block}\n",
    "pickle.dump( model, open( \"./models/hog_model.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicule Detection\n",
    "### Load the model and extract HOG parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_pickle = pickle.load( open(\"./models/hog_model.p\", \"rb\" ) )\n",
    "\n",
    "# get attributes of our svc object\n",
    "svc = dist_pickle[\"svc\"]\n",
    "orient = dist_pickle[\"orient\"]\n",
    "pix_per_cell = dist_pickle[\"pix_per_cell\"]\n",
    "cell_per_block = dist_pickle[\"cell_per_block\"]\n",
    "color_scale = dist_pickle['colorspace']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to define the image patches in which to search for vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_patches(img, first, restart, car_history):\n",
    "    h, w, _ = img.shape\n",
    "    left = int(64 * 4.65) + 1\n",
    "    right = w - int(64 * 4.65) + 1 \n",
    "    patches = []\n",
    "    # If it is the first video frame, an exhaustive search is made in the lower half of the frame.\n",
    "    if first: \n",
    "        first_patches = [(1.0, (392, 480, 0, w), 1), (1.3, (392, 497, 0, w), 1), \n",
    "                         (1.6, (392, 546, 0, w), 1), (2.0, (392, 590, 0, w), 1), \n",
    "                        (2.5, (392, 633, 0, w), 1), (2.85, (392, 666, 0, w), 1)]\n",
    "        first = False\n",
    "        return first_patches\n",
    "    # If the search restart has been activated, the search is done in patches for \n",
    "    # the horizon, and the left and right sides, the default patches.\n",
    "    elif restart:\n",
    "        patches =  [(1.0, (392, 480, 0, w), 1), \n",
    "                    (1.3, (392, 497, 0, left + int(83 * 2)), 1), (1.3, (392, 497, right - int(83 * 2), w), 1),\n",
    "                    #(1.3, (392, 497, 0, w), 1),\n",
    "                    (1.6, (392, 546, 0, left), 1), (1.6, (392, 546, right, w), 1), \n",
    "                    (2.0, (392, 590, 0, left), 1), (2.0, (392, 590, right, w), 1),\n",
    "                    (2.5, (392, 633, 0, left), 1), (2.5, (392, 633, right, w), 1),\n",
    "                    (2.85, (392, 666, 0, left), 1), (2.85, (392, 666, right, w), 1)]\n",
    "    \n",
    "    # If it is not the first frame or a search restart, the search is restricted \n",
    "    # to patches of the cars detected in the previous frame.\n",
    "    pts_previous_car = []\n",
    "    if len(car_history) > 0:\n",
    "        pts_previous_car = car_history[-1]\n",
    "        \n",
    "    for pts in pts_previous_car:\n",
    "        pt1 = pts[0]\n",
    "        pt2 = pts[1]\n",
    "        # If the car is within the left margin, the search is restricted to the entire left margin\n",
    "        if pt2[0] < left : # Car is appearing or disappearing on the left\n",
    "            new_pt1 = [0, 392]\n",
    "            xpt2 = left\n",
    "            if not restart: xpt2 += 1\n",
    "            new_pt2 = [xpt2, 651]\n",
    "        # If the car is within the right margin, the search is restricted to the entire right margin\n",
    "        elif pt1[0] > right: # Car is appearing or disappearing on the right\n",
    "            xpt1 = right\n",
    "            if not restart: xpt1 -= 1\n",
    "            new_pt1 = [xpt1, 392]\n",
    "            new_pt2 = [w, 651]\n",
    "        # If the car is not within the margins, a new search patch is created whose size is calculated \n",
    "        # on the diagonal of the car's frame, multiplied by a factor.\n",
    "        else: \n",
    "            dist = int(np.linalg.norm(pts)) + 1\n",
    "            new_dist = int(dist * 1.03)\n",
    "            aug = (new_dist - dist) // 2\n",
    "            new_pt1 = np.array(pts[0]) - aug\n",
    "            new_pt2 = np.array(pts[1]) + aug\n",
    "            \n",
    "        # Execute only if no restart or car outside left-right margin.\n",
    "        if new_pt2[0] > left and new_pt1[0] < right: \n",
    "            if new_pt1[1] < 416 and new_pt2[1] > 480: \n",
    "                patches.append((1.0, (392, 480, max(new_pt1[0],0), min(new_pt2[0],w)), 1))\n",
    "            if new_pt1[1] < 416 and new_pt2[1] > 484: \n",
    "                patches.append((1.3, (392, 497, max(new_pt1[0],0), min(new_pt2[0],w)), 1))\n",
    "            if new_pt1[1] < 420 and new_pt2[1] > 503: \n",
    "                patches.append((1.6, (392, 546, max(new_pt1[0],0), min(new_pt2[0],w)), 1))\n",
    "            if new_pt1[1] < 448 and new_pt2[1] > 528: \n",
    "                patches.append((2.0, (392, 590, max(new_pt1[0],0), min(new_pt2[0],w)), 1))\n",
    "            if new_pt2[1] > 560: \n",
    "                patches.append((2.5, (392, 633, max(new_pt1[0],0), min(new_pt2[0],w)), 1))\n",
    "            if new_pt2[1] > 603: \n",
    "                patches.append((2.85, (392, 666, max(new_pt1[0],0), min(new_pt2[0],w)), 1))\n",
    "    \n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to find cars\n",
    "By means of a sliding window and with the help of the classifier, it determines coordinates that delimit a box of a specific size where there is a vehicle in the image,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cars(img, shape, color_scale, scale, svc, orient, pix_per_cell, \n",
    "              cell_per_block, cells_per_step, all_squares=False):\n",
    "\n",
    "    # Image conversion to the range values [0,1]\n",
    "    img = img.astype(np.float32)/255 \n",
    "    \n",
    "    # Shape of the new image patch\n",
    "    ystart, ystop, xstart, xstop = shape\n",
    "    \n",
    "    # Crop the image\n",
    "    img_tosearch = img[ystart:ystop,xstart:xstop,:] \n",
    "\n",
    "    # Image conversion to a color scale\n",
    "    ctrans_tosearch = cv2.cvtColor(img_tosearch, convColor[color_scale])\n",
    "    \n",
    "    # Scale of the new image\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), \n",
    "                                                       np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    #nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # Define sampling rate and number of steps along x and y\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire patch\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    boxes = []\n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Make a prediction\n",
    "            test_prediction = svc.predict(hog_features.reshape(1,-1))\n",
    "            \n",
    "            # Create the box\n",
    "            if test_prediction == 1 or all_squares:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                box = [(xbox_left+xstart, ytop_draw+ystart),(xbox_left+win_draw+xstart,ytop_draw+win_draw+ystart)]\n",
    "                boxes.append(box)\n",
    "                \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to construct a heatmap of the box list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to filter false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funtion to draw boxes around detected vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, labels):\n",
    "    boxes = []\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "        boxes.append(bbox)\n",
    "    # Return the image\n",
    "    return img, boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function with the all steps to detect vehicles in a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    global nframes\n",
    "    global restart\n",
    "    global first\n",
    "    if nframes % 15 == 0:\n",
    "        restart = True\n",
    "    \n",
    "    patches = get_image_patches(img, first, restart, car_history)\n",
    "    restart = False\n",
    "    first = False\n",
    "\n",
    "    boxes = []\n",
    "    for scale, shape, cells_per_step in patches:\n",
    "\n",
    "        boxes_loop = find_cars(img, shape, color_scale, scale, svc, orient, pix_per_cell, \n",
    "                                 cell_per_block, cells_per_step, all_squares=False)\n",
    "        if len(boxes_loop) > 0:\n",
    "            boxes.append(boxes_loop)\n",
    "\n",
    "\n",
    "    flat_list = [item for sublist in boxes for item in sublist]\n",
    "    \n",
    "    # If there were cars in the history and they were not detected in the new frame, \n",
    "    # the oldest cars in the history are eliminated.\n",
    "    # And if there are no more cars in the history, the search is restarted.\n",
    "    if len(car_history) > 0 and len(flat_list) == 0: \n",
    "        del car_history[0] \n",
    "        if len(car_history) == 0: \n",
    "            restart = True\n",
    "    \n",
    "    # Add to the list of positive searches with the most recent cars in the history.\n",
    "    new_list = []\n",
    "    if len(flat_list) > 0:\n",
    "        new_list.append(flat_list)\n",
    "    if len(car_history) > 0 and len(flat_list) < 2:\n",
    "        new_list.append(np.concatenate(car_history))\n",
    "    elif len(car_history) > 0:\n",
    "        new_list.append(car_history[-1])\n",
    "    \n",
    "    if len(new_list) > 0:\n",
    "        new_list = np.concatenate(new_list)\n",
    "\n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    heat = add_heat(heat,new_list)            \n",
    "        \n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,1)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "    \n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    \n",
    "    # Get image of the drawn boxes and the boxes of the vehicules\n",
    "    draw_img, boxes = draw_labeled_bboxes(np.copy(img), labels)\n",
    "\n",
    "    # If any of the cars that appear in the previous frames have been lost, \n",
    "    # the search will be restarted.\n",
    "    if len(car_history) > 0:\n",
    "        prev_cars = car_history[-1]\n",
    "        if len(boxes) < len(prev_cars):\n",
    "            restart = True\n",
    "             \n",
    "    # Only one history of three frames is maintained, eliminating the oldest one.\n",
    "    if len(car_history) == 3: \n",
    "        del car_history[0]\n",
    "        \n",
    "    # If you have detected cars that are not the additions of the previous frame,\n",
    "    # they are added to the history.\n",
    "    if len(boxes) > 0 and len(flat_list) > 1: \n",
    "        car_history.append(boxes)\n",
    "    \n",
    "    nframes +=1\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes to control the process of detection\n",
    "This atributes are:\n",
    "* A flag for the first frame.\n",
    "* A counter of the number of frames for the next restart of the search.\n",
    "* A flag for the search restart.\n",
    "* A list to hold a history of vehicules from up to three previous frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "nframes = 0\n",
    "restart = True\n",
    "car_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_clip = VideoFileClip('project_video.mp4')\n",
    "clip = raw_clip.fl_image(pipeline)\n",
    "clip.write_videofile('output_videos/project_video.mp4', audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
